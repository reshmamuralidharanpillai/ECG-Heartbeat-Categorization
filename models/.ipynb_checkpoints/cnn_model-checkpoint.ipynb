{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Convolution1D, Dropout,MaxPooling1D,GlobalAveragePooling1D\n",
    "from tensorflow.keras import Model, layers,Sequential,regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import mlflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from utils import get_train_data,get_train_split,get_test_split,preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train =  get_train_split()\n",
    "X_test,y_test = get_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_processed, y_train_processed, X_test_ = preprocess(X_train,y_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_processed = to_categorical(y_train_processed, num_classes=5)\n",
    "y_test = to_categorical(y_test, num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your model architecture\n",
    "model= Sequential()\n",
    "model.add(Convolution1D(32,5,activation='relu',input_shape=(29,1)))\n",
    "model.add(Convolution1D(64,5,activation='relu'))         \n",
    "model.add(MaxPooling1D(3))\n",
    "model.add(Convolution1D(128, 3, activation='relu'))\n",
    "model.add(Convolution1D(256, 3, activation='relu'))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1024,activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(5,activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "learning_rate = 0.001  # Set the desired learning rate\n",
    "\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(patience=3, monitor='val_loss')\n",
    "\n",
    "# Train the model with early stopping\n",
    "trained_model = model.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test data\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Make predictions on new data\n",
    "train_predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the hyperparameters to tune\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "batch_sizes = [16, 32, 64]\n",
    "num_epochs = [5, 10]\n",
    "\n",
    "best_accuracy = 0.0\n",
    "best_model_path = None\n",
    "best_run_id = None\n",
    "\n",
    "def train_model(learning_rate, batch_size, num_epochs):\n",
    "\n",
    "    mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "    mlflow.log_param(\"batch_size\", batch_size)\n",
    "    mlflow.log_param(\"num_epochs\", num_epochs)\n",
    "\n",
    "    global best_accuracy\n",
    "    global best_model_path\n",
    "    global best_run_id\n",
    "    \n",
    "    # Define the model architecture\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_dim=X_train.shape[1]))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    early_stopping = EarlyStopping(patience=3, monitor='val_loss')\n",
    "    history = model.fit(X_train, y_train, epochs=num_epochs, batch_size=batch_size, validation_data=(X_val, y_val), \n",
    "                        callbacks=[early_stopping],verbose=1)\n",
    "    \n",
    "    # Evaluate the model on the validation set\n",
    "    val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
    "    \n",
    "    # Log the validation loss and accuracy\n",
    "    mlflow.log_metric(\"val_loss\", val_loss)\n",
    "    mlflow.log_metric(\"val_accuracy\", val_accuracy)\n",
    "    \n",
    "    # Check if the current model is the best so far\n",
    "    if val_accuracy > best_accuracy:\n",
    "        best_accuracy = val_accuracy\n",
    "        \n",
    "        # Save the model\n",
    "        best_model_path = f\"best_model_lr_{learning_rate}_bs_{batch_size}_epochs_{num_epochs}.h5\"\n",
    "        model.save(best_model_path)\n",
    "        \n",
    "        # Get the run ID for the best model\n",
    "        best_run_id = mlflow.active_run().info.run_id\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Iterate over the hyperparameters\n",
    "for lr in learning_rates:\n",
    "    for bs in batch_sizes:\n",
    "        for epochs in num_epochs:\n",
    "            # Start a new MLflow run\n",
    "            with mlflow.start_run(run_name=f\"lr_{lr}_bs_{bs}_epochs_{epochs}\"):\n",
    "                # Train the model\n",
    "                model = train_model(lr, bs, epochs)\n",
    "                \n",
    "                # # Log the hyperparameters only once per run\n",
    "                # if epochs == num_epochs[0]:\n",
    "                #     mlflow.log_param(\"learning_rate\", lr)\n",
    "                #     mlflow.log_param(\"batch_size\", bs)\n",
    "                #     mlflow.log_param(\"num_epochs\", epochs)\n",
    "\n",
    "# Load the best model\n",
    "best_model = tf.keras.models.load_model(best_model_path)\n",
    "\n",
    "# Print the run ID for the best model\n",
    "print(f\"Best Run ID: {best_run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the run information for the best run\n",
    "run_info = mlflow.get_run(best_run_id)\n",
    "\n",
    "# Get the hyperparameters logged for the best run\n",
    "hyperparams = run_info.data.params\n",
    "\n",
    "if 'learning_rate' in hyperparams:\n",
    "    print(f\"Learning Rate: {hyperparams['learning_rate']}\")\n",
    "\n",
    "if 'batch_size' in hyperparams:\n",
    "    print(f\"Batch Size: {hyperparams['batch_size']}\")\n",
    "\n",
    "if 'num_epochs' in hyperparams:\n",
    "    print(f\"Number of Epochs: {hyperparams['num_epochs']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test data\n",
    "loss, accuracy = best_model.evaluate(X_test, y_test)\n",
    "\n",
    "# Use the best model for predictions or other tasks\n",
    "predictions = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the predicted labels to class indices (assuming one-hot encoding)\n",
    "predicted_indices = tf.argmax(predictions, axis=1).numpy()\n",
    "\n",
    "# Convert the actual labels to class indices (assuming one-hot encoding)\n",
    "actual_indices = tf.argmax(y_test, axis=1).numpy()\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(actual_indices, predicted_indices)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, ax_acc = plt.subplots()\n",
    "plt.plot(trained_model.history['accuracy'])\n",
    "plt.plot(trained_model.history['val_accuracy'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model - Accuracy')\n",
    "plt.legend(['Training', 'Validation'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, ax_loss = plt.subplots()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Model- Loss')\n",
    "plt.legend(['Training', 'Validation'], loc='upper right')\n",
    "plt.plot(trained_model.history['loss'])\n",
    "plt.plot(trained_model.history['val_loss'])\n",
    "plt.show()\n",
    "target_names=['0','1','2','3','4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(actual_indices, predicted_indices)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_holdout_samples = 1000  # Creating 1000 new samples\n",
    "\n",
    "# Create a holdout set by randomly sampling from the training dataset\n",
    "holdout_samples_indices = np.random.choice(len(x), size=n_holdout_samples, replace=False)\n",
    "X_holdout = X_train[holdout_samples_indices]\n",
    "y_holdout = y_train[holdout_samples_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_holdout, y_holdout)\n",
    "loss, accuracy = best_model.evaluate(X_holdout, y_holdout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "8b793f5bcb65162c203a8f7ab5f10da95fa3f746ebbc21691ed336cc34611f1b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
