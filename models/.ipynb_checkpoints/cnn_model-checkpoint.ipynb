{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Convolution1D, Dropout,MaxPooling1D,GlobalAveragePooling1D\n",
    "from tensorflow.keras import Model, layers,Sequential,regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import mlflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from utils import get_train_data,get_train_split,get_test_split,preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the features and target variables from train and test dataset respectively\n",
    "X_train,y_train =  get_train_split()\n",
    "X_test,y_test = get_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess before model training\n",
    "X_train_processed, y_train_processed, X_test_ = preprocess(X_train,y_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert labels to one-hot encoded format\n",
    "y_train_processed = to_categorical(y_train_processed, num_classes=5)\n",
    "y_test = to_categorical(y_test, num_classes=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network(CNN)\n",
    "The CNN algorithm performs classification better than conventional approaches and does not require feature extraction. The original ECG signals can be directly classified, and any human intervention is removed. Different levels of abstraction can be captured by CNNs in terms of local patterns and features. The convolutional, max pooling, and dense layers that make up the 1D-CNN model architecture automatically extract distinct nonlinear features from the ECG data and automatically categorise them into five separate classes. Additionally, parameter sharing is used by CNNs, where the same set of weights are applied to many input regions. By sharing parameters, CNNs become more computationally efficient and have a lower chance of overfitting, especially when there is a shortage of training data.\n",
    "\n",
    "Some potential challenges associated with CNNs are as follows:\n",
    "* CNN models are frequently referred to as \"black-box models,\" which makes it difficult to evaluate and comprehend how they make decisions. Interpretability is especially important in the healthcare industry since it can increase confidence and provide insights into the clinical consequences of the forecasts. \n",
    "*CNN models can be computationally taxing, particularly when working with more substantial and intricate designs or large datasets. To achieve reasonable training times, training and inference methods may need high-performance hardware or distributed computing resources.\n",
    "\n",
    "These challenges can be addressed by exploring interpretability methods specific to CNN models in healthcare applications. Additionally, optimizing and parallelizing computations on hardware accelerators (e.g., GPUs) can help overcome computational resource constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model architecture\n",
    "model= Sequential()\n",
    "model.add(Convolution1D(32,5,activation='relu',input_shape=(29,1)))\n",
    "model.add(Convolution1D(64,5,activation='relu'))         \n",
    "model.add(MaxPooling1D(3))\n",
    "model.add(Convolution1D(128, 3, activation='relu'))\n",
    "model.add(Convolution1D(256, 3, activation='relu'))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1024,activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(5,activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "learning_rate = 0.001  # Setting the desired learning rate\n",
    "\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(patience=3, monitor='val_loss')\n",
    "\n",
    "# Train the model with early stopping\n",
    "trained_model = model.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid overfitting or underfitting, increase efficiency, and determine the ideal stopping point based on the model's performance, early stopping and training callbacks are approaches used during model training.\n",
    "\n",
    "* Training Callbacks: TensorFlow's training callbacks offer a mechanism to alter the training procedure by carrying out particular tasks at different training phases. Callbacks are objects or procedures that can be provided to a Keras model's fit() method. They are carried out during training at predetermined times, such as the beginning or end of an epoch, just before or just after batch processing, or when a particular metric threshold is reached. When adding new features or behaviours to training, such as early stopping, scheduling learning rates, model checkpointing, or logging metrics, training callbacks are employed. By enabling dynamic adjustments to the training process without interfering with or manually altering the training loop, they increase efficiency. I have implemented Early Stopping as a callback that monitors a specific metric during training.\n",
    "\n",
    "* Early Stopping: The training process can be ended early using the early stopping strategy if the model's performance on a validation set remains unchanged or worsens. By minimising pointless training iterations that can result in memory of the training data, it helps minimise overfitting. Early termination is based on the observation that the model's performance on the validation set tends to approach an ideal level as training advances and may start to degrade if training is continued. Early stopping, which monitors a particular metric (such validation loss or accuracy), terminates the training procedure when the metric does not improve after a specified number of epochs (patience). By avoiding overfitting, this method aids in striking the correct balance between model performance.\n",
    "\n",
    "The EarlyStopping callback in Keras implemented in this project waits for 3 epochs without improvement in the monitored metric before stopping the training process. The metric to be monitored is assigned as validation loss.\n",
    "\n",
    "A regularisation method frequently employed in neural networks, especially deep learning models, is the dropout layer. It enhances the model's capacity for generalisation and helps avoid overfitting. The dropout layer works by randomly setting a fraction of input units to 0 at each update during training time, which temporarily removes those units from the network. The dropout layer used in the CNN model of this project has a dropout rate of 0.3. This means that approximately 30% of the input units will be dropped out or set to 0 at each update.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test data\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Make predictions on test data\n",
    "train_predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "I have chosen the following hyperparameters for hyperparameter tuning - learning rate, epochs, and batch size. The methodology used for tuning these hyperparameters is through the utilization of MLflow.\n",
    "\n",
    "* Learning Rate: As the model's parameters are updated during training, the learning rate is a hyperparameter that sets the step size at each iteration. It controls the speed and magnitude of parameter updates. The learning rate is a crucial hyperparameter to adjust because it can cause unstable training or overshooting at high values and delayed convergence or getting stuck in local minima at low values. I tried with several learning rate values, such as 0.001, 0.01, and 0.1, to discover the best learning rate that strikes a balance between training efficiency and model performance.\n",
    "\n",
    "* Epochs: During model training, an epoch represents a full iteration of the entire training dataset. A hyperparameter that controls how frequently the model is exposed to training data is the number of epochs. The performance of the model may be enhanced by increasing the number of epochs, but there is a risk of overfitting if the model begins to memorise the training data too thoroughly. I ran multiple learning runs with various epoch values, such as 5, 10, and then tuned the number of epochs by observing the model's performance on validation data and using early stopping approaches to find the right number of epochs that maximise performance without overfitting.\n",
    "\n",
    "* Batch Size: The batch size is a hyperparameter that determines the number of samples presented to the model for evaluation and parameter updates at each iteration. It affects both training time and the quality of parameter updates. Smaller batch sizes can provide more frequent updates, leading to faster convergence. Larger batch sizes can stabilize training but may require more memory and computational resources. To tune the batch size, I experimented with various values, such as 16, 32, 64, and observed the trade-off between training speed and convergence stability.\n",
    "\n",
    "The code iterates over hyperparameters and start a new MLflow run for each combination. For each combination, performance metrics are logged using MLflow. Validation data splits is also used to evaluate and compare the models' performance with different hyperparameter settings. MLflow provides a convenient framework to track and record these hyperparameter values, along with corresponding performance metrics, enabling efficient experimentation and analysis of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the hyperparameters to tune\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "batch_sizes = [16, 32, 64]\n",
    "num_epochs = [5, 10]\n",
    "\n",
    "best_accuracy = 0.0\n",
    "best_model_path = None\n",
    "best_run_id = None\n",
    "\n",
    "def train_model(learning_rate, batch_size, num_epochs):\n",
    "\n",
    "    mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "    mlflow.log_param(\"batch_size\", batch_size)\n",
    "    mlflow.log_param(\"num_epochs\", num_epochs)\n",
    "\n",
    "    global best_accuracy\n",
    "    global best_model_path\n",
    "    global best_run_id\n",
    "    \n",
    "    # Define the model architecture\n",
    "    model= Sequential()\n",
    "    model.add(Convolution1D(32,5,activation='relu',input_shape=(29,1)))\n",
    "    model.add(Convolution1D(64,5,activation='relu'))         \n",
    "    model.add(MaxPooling1D(3))\n",
    "    model.add(Convolution1D(128, 3, activation='relu'))\n",
    "    model.add(Convolution1D(256, 3, activation='relu'))\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1024,activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(256,activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(32,activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(5,activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    early_stopping = EarlyStopping(patience=3, monitor='val_loss')\n",
    "    history = model.fit(X_train, y_train, epochs=num_epochs, batch_size=batch_size, validation_data=(X_val, y_val), \n",
    "                        callbacks=[early_stopping],verbose=1)\n",
    "    \n",
    "    # Evaluate the model on the validation set\n",
    "    val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
    "    \n",
    "    # Log the validation loss and accuracy\n",
    "    mlflow.log_metric(\"val_loss\", val_loss)\n",
    "    mlflow.log_metric(\"val_accuracy\", val_accuracy)\n",
    "    \n",
    "    # Check if the current model is the best so far\n",
    "    if val_accuracy > best_accuracy:\n",
    "        best_accuracy = val_accuracy\n",
    "        \n",
    "        # Save the model\n",
    "        best_model_path = f\"best_model_lr_{learning_rate}_bs_{batch_size}_epochs_{num_epochs}.h5\"\n",
    "        model.save(best_model_path)\n",
    "        \n",
    "        # Get the run ID for the best model\n",
    "        best_run_id = mlflow.active_run().info.run_id\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Iterate over the hyperparameters\n",
    "for lr in learning_rates:\n",
    "    for bs in batch_sizes:\n",
    "        for epochs in num_epochs:\n",
    "            # Start a new MLflow run\n",
    "            with mlflow.start_run(run_name=f\"lr_{lr}_bs_{bs}_epochs_{epochs}\"):\n",
    "                # Train the model\n",
    "                model = train_model(lr, bs, epochs)\n",
    "                \n",
    "\n",
    "# Load the best model\n",
    "best_model = tf.keras.models.load_model(best_model_path)\n",
    "\n",
    "# Print the run ID for the best model\n",
    "print(f\"Best Run ID: {best_run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the run information for the best run\n",
    "run_info = mlflow.get_run(best_run_id)\n",
    "\n",
    "# Get the hyperparameters logged for the best run\n",
    "hyperparams = run_info.data.params\n",
    "\n",
    "if 'learning_rate' in hyperparams:\n",
    "    print(f\"Learning Rate: {hyperparams['learning_rate']}\")\n",
    "\n",
    "if 'batch_size' in hyperparams:\n",
    "    print(f\"Batch Size: {hyperparams['batch_size']}\")\n",
    "\n",
    "if 'num_epochs' in hyperparams:\n",
    "    print(f\"Number of Epochs: {hyperparams['num_epochs']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best model on test data\n",
    "loss, accuracy = best_model.evaluate(X_test, y_test)\n",
    "\n",
    "# Use the best model for predictions or other tasks\n",
    "predictions = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the predicted labels to class indices\n",
    "predicted_indices = tf.argmax(predictions, axis=1).numpy()\n",
    "\n",
    "# Convert the actual labels to class indices\n",
    "actual_indices = tf.argmax(y_test, axis=1).numpy()\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(actual_indices, predicted_indices)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot showing the Training and Validation Accuracy\n",
    "fig1, ax_acc = plt.subplots()\n",
    "plt.plot(trained_model.history['accuracy'])\n",
    "plt.plot(trained_model.history['val_accuracy'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model - Accuracy')\n",
    "plt.legend(['Training', 'Validation'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot showing the Training and Validation Loss\n",
    "fig2, ax_loss = plt.subplots()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Model- Loss')\n",
    "plt.legend(['Training', 'Validation'], loc='upper right')\n",
    "plt.plot(trained_model.history['loss'])\n",
    "plt.plot(trained_model.history['val_loss'])\n",
    "plt.show()\n",
    "target_names=['0','1','2','3','4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(actual_indices, predicted_indices)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy and Confusion matrix were chosen as the evaluation metrics for the classification task of heartbeat signals into different arrhythmia cases. These metrics are commonly used and well-suited for such tasks. However, if the task involved binary classification, such as identifying infected cases or anomaly detection, Recall would be a more appropriate evaluation metric. Recall specifically focuses on correctly predicting positive instances out of all actual positive instances, making it particularly relevant for such scenarios.\n",
    "\n",
    "* Accuracy: Accuracy is a common metric that measures the overall correctness of the model's predictions. It calculates the ratio of correctly predicted samples to the total number of samples in the dataset. \n",
    "* Confusion Matrix: A confusion matrix provides a detailed breakdown of the model's predictions for each class. It shows the number of true positives, true negatives, false positives, and false negatives. \n",
    "\n",
    "The initial model showed satisfactory accuracy during training. However, to further enhance the model's performance and accuracy, hyperparameter tuning was done. This process helped find the optimal combination of hyperparameters that led to improved results. The model trained using the best hyperparameters achieved higher accuracy during validation, indicating an enhancement in its performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a holdout set by randomly sampling from the training dataset\n",
    "n_holdout_samples = 1000  # Creating 1000 new samples\n",
    "\n",
    "holdout_samples_indices = np.random.choice(len(x), size=n_holdout_samples, replace=False)\n",
    "X_holdout = X_train[holdout_samples_indices]\n",
    "y_holdout = y_train[holdout_samples_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_holdout, y_holdout)\n",
    "loss, accuracy = best_model.evaluate(X_holdout, y_holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The holdout data exhibited comparable performance to the training data. Both the trained model and the best model achieved good accuracy, with the best model slightly outperforming the trained model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "8b793f5bcb65162c203a8f7ab5f10da95fa3f746ebbc21691ed336cc34611f1b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
